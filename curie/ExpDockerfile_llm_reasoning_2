# Base image with Python and Conda
FROM continuumio/miniconda3:latest

# Set the working directory inside the container
WORKDIR /exp_agent

# Copy the current directory into the container
COPY ./src /exp_agent
COPY ./benchmark /benchmark
COPY ./starter_file /starter_file
# COPY ./eval_metadata /eval_metadata

# Install dependencies from the Conda environment file
RUN conda env create -f environment.yml && \
    conda clean -a

RUN conda create -n impact python=3.8.18 && \
    conda clean -a

RUN /opt/conda/bin/conda init bash

# Set the environment path for the Conda environment: this is used for llm reasoning 2 for now
RUN echo "source activate impact" > ~/.bashrc && \
    /bin/bash -c "source ~/.bashrc && \
    pip install torch==1.8.2+cu111 torchtext==0.9.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html && \
    pip install -r /starter_file/The-Impact-of-Reasoning-Step-Length-on-Large-Language-Models/requirements.txt"

# Update the package list and install vim
RUN apt-get update && apt-get install -y vim

RUN mkdir -p /workspace
RUN mkdir -p /temp/logs/

# Setup OpenAI credentials: this is currently useful for LLM reasoning 2
RUN chmod +x setup/env.sh
RUN . setup/env.sh

# Set PATH to activate the Conda environment automatically in the container
ENV PATH=/opt/conda/envs/langgraph/bin:$PATH

# Ensure bash is the default shell
SHELL ["/bin/bash", "-c"]

# Default command
# CMD ["bash"]
# Keep container running
CMD ["tail", "-f", "/dev/null"]